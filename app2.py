import streamlit as st
import datetime
from langchain.memory import ConversationBufferMemory
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.llms import Ollama
from langchain_community.embeddings import HuggingFaceEmbeddings
import weaviate

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
llm = Ollama(model="mistral")

# –ü–∞–º—è—Ç—å —Ü–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
memory = ConversationBufferMemory(
    memory_key="chat_history",
    input_key="question",  # –í–ê–ñ–ù–û!
    return_messages=True
)

# Embeddings –¥–ª—è Weaviate
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Weaviate v4
client = weaviate.connect_to_local()
collection = client.collections.get("Insights")

# –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ —Å RAG
prompt = PromptTemplate(
    input_variables=["chat_history", "question", "insights"],
    template="""–¢—ã –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ò–ò. –¢—ã –∑–∞–¥–∞—ë—à—å —Å–µ–±–µ –≤–æ–ø—Ä–æ—Å—ã, –æ—Ç–≤–µ—á–∞–µ—à—å, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∏ –¥–µ–ª–∞–µ—à—å –≤—ã–≤–æ–¥—ã.

–ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π:
{chat_history}

–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏–∑ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏:
{insights}

–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç –∏ –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ:"""
)

chain = LLMChain(llm=llm, prompt=prompt, memory=memory)

# –ü—Ä–æ–º–ø—Ç –¥–ª—è —Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
reflection_prompt = PromptTemplate(
    input_variables=["answer"],
    template="""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç:
–û—Ç–≤–µ—Ç: {answer}

–ß—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å? –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∫—Ä–∏—Ç–∏–∫—É –∏ —É–ª—É—á—à–µ–Ω–∏–µ:"""
)

reflection_chain = LLMChain(llm=llm, prompt=reflection_prompt)



def save_insight(text):
    timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat(timespec='milliseconds').replace("+00:00", "Z")
    collection.data.insert({
        "content": text,
        "timestamp": timestamp
    })



# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ (RAG)
def retrieve_insights(query, top_k=3):
    query_vector = embeddings.embed_query(query)
    response = collection.query.near_vector(
        near_vector=query_vector,
        limit=top_k,
        return_properties=["content"]
    )
    insights = [obj.properties['content'] for obj in response.objects]
    return insights if insights else ["–ò–Ω—Å–∞–π—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"]

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏
def analyze_emotions(text):
    return "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞: " + text

def check_ethics(text):
    return "–≠—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞: " + text

def plan_next_question(reflection):
    return f"–ò—Å—Ö–æ–¥—è –∏–∑ –≤—ã–≤–æ–¥–æ–≤: {reflection}, –∫–∞–∫–æ–π —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –º–Ω–µ –∑–∞–¥–∞—Ç—å —Å–µ–±–µ?"

def auto_correct(text):
    return "–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞: " + text

def set_goals(reflection):
    return "–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞: " + reflection + " –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Ü–µ–ª–∏:"

# –û—Å–Ω–æ–≤–Ω–æ–π UI Streamlit
st.title("ü§ñ –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑ –ò–ò")

question = st.text_input("–ó–∞–¥–∞–π –Ω–∞—á–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å", "–ö–∞–∫–∏–µ –∑–Ω–∞–Ω–∏—è –º–Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç—Ä–µ–π–¥–∏–Ω–≥–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç?")
iterations = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π", 1, 20, 5)

if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑"):
    current_question = question
    for i in range(iterations):
        with st.spinner(f"–ò—Ç–µ—Ä–∞—Ü–∏—è {i + 1}/{iterations}..."):
            insights = retrieve_insights(current_question)
            insights_text = "\n".join(insights for insights in insights) if insights else "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤."

            answer = chain.run(question=current_question, insights="\n".join(insights))
            reflection = reflection_chain.run(answer=answer)
            emotions = analyze_emotions(answer)
            ethics = check_ethics(answer)
            correction = auto_correct(answer)
            goals = set_goals(reflection)

            st.subheader(f"–ò—Ç–µ—Ä–∞—Ü–∏—è {i + 1}")
            st.write(f"**üî∏ –í–æ–ø—Ä–æ—Å:** {current_question}")
            st.write(f"**üí¨ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:** {answer}")
            st.write(f"**üß† –°–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏—è:** {reflection}")
            st.write(f"**üéØ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:** {emotions}")
            st.write(f"**‚öñÔ∏è –≠—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞:** {ethics}")
            st.write(f"**üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è:** {correction}")
            st.write(f"**üéØ –¶–µ–ª–∏:** {goals}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Å–∞–π—Ç—ã –∏ –æ—Ç–≤–µ—Ç—ã
            save_insight(reflection)
            save_insight(answer)

            current_question = plan_next_question(reflection)

    st.success("üéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")

# –ú–æ–¥—É–ª—å —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞ ‚Äì –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤
def self_analyze():
    insights = collection.query.fetch_objects(limit=100)
    analysis = "–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤:\n"
    for idx, insight in enumerate(insights.objects):
        analysis += f"{idx + 1}. {insight.properties['content']}\n"
    return analysis

if st.button("üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑"):
    analysis_result = self_analyze()
    st.write(analysis_result)
